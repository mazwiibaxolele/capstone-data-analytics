{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"text-align:center\">\n",
    "    <a href=\"https://skills.network\" target=\"_blank\">\n",
    "    <img src=\"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/assets/logos/SN_web_lightmode.png\" width=\"200\" alt=\"Skills Network Logo\"  />\n",
    "    </a>\n",
    "</p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Data Wrangling Lab**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Estimated time needed: **45** minutes\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this lab, you will perform data wrangling tasks to prepare raw data for analysis. Data wrangling involves cleaning, transforming, and organizing data into a structured format suitable for analysis. This lab focuses on tasks like identifying inconsistencies, encoding categorical variables, and feature transformation.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Objectives\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After completing this lab, you will be able to:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Identify and remove inconsistent data entries.\n",
    "\n",
    "- Encode categorical variables for analysis.\n",
    "\n",
    "- Handle missing values using multiple imputation strategies.\n",
    "\n",
    "- Apply feature scaling and transformation techniques.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Intsall the required libraries\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pandas\n",
    "!pip install matplotlib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tasks\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 1: Import the necessary module.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Load the Dataset\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h5>1.1 Import necessary libraries and load the dataset.</h5>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ensure the dataset is loaded correctly by displaying the first few rows.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "\n",
    "# Load the Stack Overflow survey data\n",
    "dataset_url = \"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/n01PQ9pSmiRX6520flujwQ/survey-data.csv\"\n",
    "df = pd.read_csv(dataset_url)\n",
    "\n",
    "# Display the first few rows\n",
    "print(df.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Explore the Dataset\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h5>2.1 Summarize the dataset by displaying the column data types, counts, and missing values.</h5>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Information:\n",
      "============================================================\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 65437 entries, 0 to 65436\n",
      "Columns: 114 entries, ResponseId to JobSat\n",
      "dtypes: float64(13), int64(1), object(100)\n",
      "memory usage: 56.9+ MB\n",
      "None\n",
      "\n",
      "============================================================\n",
      "\n",
      "Dataset Shape: (65437, 114)\n",
      "Number of rows: 65437\n",
      "Number of columns: 114\n",
      "\n",
      "============================================================\n",
      "\n",
      "Missing Values Summary:\n",
      "                            Missing Count  Percentage\n",
      "AINextMuch less integrated          64289   98.245641\n",
      "AINextLess integrated               63082   96.401119\n",
      "AINextNo change                     52939   80.900714\n",
      "AINextMuch more integrated          51999   79.464217\n",
      "EmbeddedAdmired                     48704   74.428840\n",
      "...                                   ...         ...\n",
      "YearsCode                            5568    8.508948\n",
      "NEWSOSites                           5151    7.871693\n",
      "LearnCode                            4949    7.563000\n",
      "EdLevel                              4653    7.110656\n",
      "AISelect                             4530    6.922689\n",
      "\n",
      "[109 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "# Display dataset information\n",
    "print(\"Dataset Information:\")\n",
    "print(\"=\"*60)\n",
    "print(df.info())\n",
    "\n",
    "print(\"\\n\" + \"=\"*60 + \"\\n\")\n",
    "\n",
    "# Display shape\n",
    "print(f\"Dataset Shape: {df.shape}\")\n",
    "print(f\"Number of rows: {df.shape[0]}\")\n",
    "print(f\"Number of columns: {df.shape[1]}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60 + \"\\n\")\n",
    "\n",
    "# Display missing values\n",
    "print(\"Missing Values Summary:\")\n",
    "missing_values = df.isnull().sum()\n",
    "missing_percentage = (missing_values / len(df)) * 100\n",
    "missing_df = pd.DataFrame({\n",
    "    'Missing Count': missing_values,\n",
    "    'Percentage': missing_percentage\n",
    "})\n",
    "print(missing_df[missing_df['Missing Count'] > 0].sort_values('Missing Count', ascending=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h5>2.2 Generate basic statistics for numerical columns.</h5>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate basic statistics for numerical columns\n",
    "print(\"Basic Statistics for Numerical Columns:\")\n",
    "print(\"=\"*60)\n",
    "print(df.describe())\n",
    "\n",
    "print(\"\\n\" + \"=\"*60 + \"\\n\")\n",
    "\n",
    "# Additional statistics for numerical columns\n",
    "numerical_cols = df.select_dtypes(include=['int64', 'float64']).columns\n",
    "print(f\"Numerical columns: {list(numerical_cols)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Identifying and Removing Inconsistencies\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h5>3.1 Identify inconsistent or irrelevant entries in specific columns (e.g., Country).</h5>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique values in 'Country' column:\n",
      "Country\n",
      "United States of America                                11095\n",
      "Germany                                                  4947\n",
      "India                                                    4231\n",
      "United Kingdom of Great Britain and Northern Ireland     3224\n",
      "Ukraine                                                  2672\n",
      "                                                        ...  \n",
      "Micronesia, Federated States of...                          1\n",
      "Nauru                                                       1\n",
      "Chad                                                        1\n",
      "Djibouti                                                    1\n",
      "Solomon Islands                                             1\n",
      "Name: count, Length: 185, dtype: int64\n",
      "\n",
      "============================================================\n",
      "\n",
      "Total unique countries: 185\n",
      "Missing values in Country: 6507\n",
      "\n",
      "Sample Country entries:\n",
      "0                              United States of America\n",
      "1     United Kingdom of Great Britain and Northern I...\n",
      "2     United Kingdom of Great Britain and Northern I...\n",
      "3                                                Canada\n",
      "4                                                Norway\n",
      "5                              United States of America\n",
      "6                              United States of America\n",
      "7                                            Uzbekistan\n",
      "8     United Kingdom of Great Britain and Northern I...\n",
      "9                                                Serbia\n",
      "10                             United States of America\n",
      "11                                               Poland\n",
      "12                             United States of America\n",
      "13                                          Philippines\n",
      "14                                             Bulgaria\n",
      "15                                          Switzerland\n",
      "16                                               Canada\n",
      "17                                                India\n",
      "18                                              Germany\n",
      "19    United Kingdom of Great Britain and Northern I...\n",
      "Name: Country, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Identify unique values in Country column\n",
    "print(\"Unique values in 'Country' column:\")\n",
    "print(df['Country'].value_counts())\n",
    "\n",
    "print(\"\\n\" + \"=\"*60 + \"\\n\")\n",
    "\n",
    "# Check for potential inconsistencies\n",
    "print(f\"Total unique countries: {df['Country'].nunique()}\")\n",
    "print(f\"Missing values in Country: {df['Country'].isnull().sum()}\")\n",
    "\n",
    "# Display some examples\n",
    "print(\"\\nSample Country entries:\")\n",
    "print(df['Country'].head(20))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h5>3.2 Standardize entries in columns like Country or EdLevel by mapping inconsistent values to a consistent format.</h5>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Country values after standardization:\n",
      "Country\n",
      "United States                                           11095\n",
      "Germany                                                  4947\n",
      "India                                                    4231\n",
      "United Kingdom of Great Britain and Northern Ireland     3224\n",
      "Ukraine                                                  2672\n",
      "France                                                   2110\n",
      "Canada                                                   2104\n",
      "Poland                                                   1534\n",
      "Netherlands                                              1449\n",
      "Brazil                                                   1375\n",
      "Name: count, dtype: int64\n",
      "\n",
      "============================================================\n",
      "\n",
      "Unique EdLevel values:\n",
      "EdLevel\n",
      "Bachelor’s degree (B.A., B.S., B.Eng., etc.)                                          24942\n",
      "Master’s degree (M.A., M.S., M.Eng., MBA, etc.)                                       15557\n",
      "Some college/university study without earning a degree                                 7651\n",
      "Secondary school (e.g. American high school, German Realschule or Gymnasium, etc.)     5793\n",
      "Professional degree (JD, MD, Ph.D, Ed.D, etc.)                                         2970\n",
      "Associate degree (A.A., A.S., etc.)                                                    1793\n",
      "Primary/elementary school                                                              1146\n",
      "Something else                                                                          932\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Standardize Country entries (example mapping)\n",
    "# Create a mapping dictionary for common inconsistencies\n",
    "country_mapping = {\n",
    "    'USA': 'United States',\n",
    "    'US': 'United States',\n",
    "    'U.S.': 'United States',\n",
    "    'United States of America': 'United States',\n",
    "    'UK': 'United Kingdom',\n",
    "    'U.K.': 'United Kingdom',\n",
    "    'Britain': 'United Kingdom'\n",
    "}\n",
    "\n",
    "# Apply the mapping\n",
    "df['Country'] = df['Country'].replace(country_mapping)\n",
    "\n",
    "print(\"Country values after standardization:\")\n",
    "print(df['Country'].value_counts().head(10))\n",
    "\n",
    "print(\"\\n\" + \"=\"*60 + \"\\n\")\n",
    "\n",
    "# Standardize EdLevel if needed\n",
    "if 'EdLevel' in df.columns:\n",
    "    print(\"Unique EdLevel values:\")\n",
    "    print(df['EdLevel'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Encoding Categorical Variables\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h5>4.1 Encode the Employment column using one-hot encoding.</h5>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Write your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Handling Missing Values\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h5>5.1 Identify columns with the highest number of missing values.</h5>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Write your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h5>5.2 Impute missing values in numerical columns (e.g., `ConvertedCompYearly`) with the mean or median.</h5>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Write your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h5>5.3 Impute missing values in categorical columns (e.g., `RemoteWork`) with the most frequent value.</h5>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Write your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Feature Scaling and Transformation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h5>6.1 Apply Min-Max Scaling to normalize the `ConvertedCompYearly` column.</h5>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Write your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h5>6.2 Log-transform the ConvertedCompYearly column to reduce skewness.</h5>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Write your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Feature Engineering\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h5>7.1 Create a new column `ExperienceLevel` based on the `YearsCodePro` column:</h5>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Write your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this lab, you:\n",
    "\n",
    "- Explored the dataset to identify inconsistencies and missing values.\n",
    "\n",
    "- Encoded categorical variables for analysis.\n",
    "\n",
    "- Handled missing values using imputation techniques.\n",
    "\n",
    "- Normalized and transformed numerical data to prepare it for analysis.\n",
    "\n",
    "- Engineered a new feature to enhance data interpretation.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copyright © IBM Corporation. All rights reserved.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  },
  "prev_pub_hash": "1e8e234f19fd098e27b0518a87f18de690e1c51f1d3263d5690927d19971251e"
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
